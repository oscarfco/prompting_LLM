{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8525e51-d047-4ccd-b7ad-408896ad1b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 16 23:05:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    44W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  Off  | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    45W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100 80G...  Off  | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    45W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100 80G...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    42W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100 80G...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    43W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100 80G...  Off  | 00000000:09:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    45W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100 80G...  Off  | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    44W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100 80G...  Off  | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    64W / 300W |   1806MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    7   N/A  N/A   2132222      C                                    1803MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a1db93f-1b70-4852-b803-ac085a2c6dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66fe1ea4-4eb2-49ff-a350-d579617ecb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MANIFEST_SESSION_HOME=\"/home/ahojel/ama_prompting/manifest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8360f3-1125-4851-81a3-a4c7e3ec8887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoo model not available.\n",
      "Model Name: EleutherAI/gpt-neo-1.3B Model Path: EleutherAI/gpt-neo-1.3B\n",
      "Loaded Model DType torch.float32\n",
      "Usings max_length: 2048\n",
      " * Serving Flask app 'app'\n",
      " * Debug mode: off\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5005\n",
      " * Running on http://192.168.122.3:5005\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [16/Nov/2022 23:17:26] \"POST /params HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Nov/2022 23:17:26] \"POST /params HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# make sure to change model_name if you want 1.3B and device if nvidia-smi device id is being used!\n",
    "!python3 manifest/manifest/api/app.py \\\n",
    "        --port 5005 --model_type huggingface \\\n",
    "        --model_name EleutherAI/gpt-neo-1.3B \\\n",
    "        --cache_dir /home/ahojel/transformers_cache \\\n",
    "        --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a250dc-e9ce-4f5c-a93d-b0d10bf84022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
